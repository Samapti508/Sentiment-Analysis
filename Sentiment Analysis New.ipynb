{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44798266",
   "metadata": {},
   "source": [
    "Installing Necessaary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "509bc693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.2.2\n",
      "  Obtaining dependency information for scikit-learn==1.2.2 from https://files.pythonhosted.org/packages/db/98/169b46a84b48f92df2b5e163fce75d471f4df933f8b3d925a61133210776/scikit_learn-1.2.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.2.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\samapti\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\samapti\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\samapti\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\samapti\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (2.2.0)\n",
      "Downloading scikit_learn-1.2.2-cp311-cp311-win_amd64.whl (8.3 MB)\n",
      "   ---------------------------------------- 0.0/8.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/8.3 MB 1.1 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.2/8.3 MB 1.7 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.3/8.3 MB 2.0 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.5/8.3 MB 2.6 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.7/8.3 MB 2.7 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.0/8.3 MB 3.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.2/8.3 MB 3.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.3/8.3 MB 3.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.6/8.3 MB 3.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.8/8.3 MB 3.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.9/8.3 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.2/8.3 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.3/8.3 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.5/8.3 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.7/8.3 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.9/8.3 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.2/8.3 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.3/8.3 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.6/8.3 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.8/8.3 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.1/8.3 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.3/8.3 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.5/8.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.7/8.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.0/8.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.2/8.3 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.4/8.3 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.7/8.3 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.0/8.3 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.3/8.3 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.5/8.3 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.7/8.3 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.9/8.3 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.2/8.3 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.5/8.3 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.7/8.3 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.3 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.2/8.3 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.3/8.3 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.3/8.3 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.3/8.3 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.3/8.3 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.3/8.3 MB 4.0 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.0\n",
      "    Uninstalling scikit-learn-1.3.0:\n",
      "      Successfully uninstalled scikit-learn-1.3.0\n",
      "Successfully installed scikit-learn-1.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "farm-haystack 1.25.0 requires scikit-learn>=1.3.0, but you have scikit-learn 1.2.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a72aeb",
   "metadata": {},
   "source": [
    "Importing Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa72423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d917f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.functional import cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eed9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "  import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7313428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3284ad02",
   "metadata": {},
   "source": [
    "The Dataset contain product_name, Rate , Review, Summary which is descriptive informationn of customer's thought on each product and Sentiment based on Summary. We will use Summary and Sentiment column for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da005bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>5</td>\n",
       "      <td>super!</td>\n",
       "      <td>great cooler excellent air flow and for this p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>5</td>\n",
       "      <td>awesome</td>\n",
       "      <td>best budget 2 fit cooler nice cooling</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>3</td>\n",
       "      <td>fair</td>\n",
       "      <td>the quality is good but the power of air is de...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>1</td>\n",
       "      <td>useless product</td>\n",
       "      <td>very bad product its a only a fan</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>3</td>\n",
       "      <td>fair</td>\n",
       "      <td>ok ok product</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name product_price Rate  \\\n",
       "0  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
       "1  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
       "2  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
       "3  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    1   \n",
       "4  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
       "\n",
       "            Review                                            Summary  \\\n",
       "0           super!  great cooler excellent air flow and for this p...   \n",
       "1          awesome              best budget 2 fit cooler nice cooling   \n",
       "2             fair  the quality is good but the power of air is de...   \n",
       "3  useless product                  very bad product its a only a fan   \n",
       "4             fair                                      ok ok product   \n",
       "\n",
       "  Sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4   neutral  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Flipkart_Product_Review.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d3c2881",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205052"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b5f99cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name     object\n",
       "product_price    object\n",
       "Rate             object\n",
       "Review           object\n",
       "Summary          object\n",
       "Sentiment        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49951331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name         0\n",
       "product_price        0\n",
       "Rate                 0\n",
       "Review           24664\n",
       "Summary             11\n",
       "Sentiment            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dd02ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Rate' column to numeric, coercing errors to NaN\n",
    "df['Rate'] = pd.to_numeric(df['Rate'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4831c794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name      object\n",
       "product_price     object\n",
       "Rate             float64\n",
       "Review            object\n",
       "Summary           object\n",
       "Sentiment         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e20bc91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name         0\n",
       "product_price        0\n",
       "Rate                 3\n",
       "Review           24664\n",
       "Summary             11\n",
       "Sentiment            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8a8cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate = df.dropna(subset=['Rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "994de301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>MAHARAJA WHITELINE 65 L Desert Air Cooler?????...</td>\n",
       "      <td>7999</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nice</td>\n",
       "      <td>received dalay 10 days cooler is ok when i was...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>MAHARAJA WHITELINE 65 L Desert Air Cooler?????...</td>\n",
       "      <td>7999</td>\n",
       "      <td>3.0</td>\n",
       "      <td>just okay</td>\n",
       "      <td>not so good</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>MAHARAJA WHITELINE 65 L Desert Air Cooler?????...</td>\n",
       "      <td>7999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>perfect product!</td>\n",
       "      <td>not working motors and very bad poor maharaja ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>MAHARAJA WHITELINE 65 L Desert Air Cooler?????...</td>\n",
       "      <td>7999</td>\n",
       "      <td>3.0</td>\n",
       "      <td>just okay</td>\n",
       "      <td>product quality is very bad and fan blade brok...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>MAHARAJA WHITELINE 65 L Desert Air Cooler?????...</td>\n",
       "      <td>7999</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nice</td>\n",
       "      <td>cooler is good but very dirty smell</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204998</th>\n",
       "      <td>cello Pack of 18 Opalware Cello Dazzle Lush Fi...</td>\n",
       "      <td>1299</td>\n",
       "      <td>3.0</td>\n",
       "      <td>just okay</td>\n",
       "      <td>i expected that this dinner set might be compa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205012</th>\n",
       "      <td>cello Pack of 18 Opalware Cello Dazzle Lush Fi...</td>\n",
       "      <td>1299</td>\n",
       "      <td>5.0</td>\n",
       "      <td>just wow!</td>\n",
       "      <td>plates are small</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205014</th>\n",
       "      <td>cello Pack of 18 Opalware Cello Dazzle Lush Fi...</td>\n",
       "      <td>1299</td>\n",
       "      <td>3.0</td>\n",
       "      <td>fair</td>\n",
       "      <td>dinner plates is too small</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205016</th>\n",
       "      <td>cello Pack of 18 Opalware Cello Dazzle Lush Fi...</td>\n",
       "      <td>1299</td>\n",
       "      <td>3.0</td>\n",
       "      <td>fair</td>\n",
       "      <td>small size</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205032</th>\n",
       "      <td>cello Pack of 18 Opalware Cello Dazzle Lush Fi...</td>\n",
       "      <td>1299</td>\n",
       "      <td>3.0</td>\n",
       "      <td>just okay</td>\n",
       "      <td>bowls are small size</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4731 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             product_name product_price  Rate  \\\n",
       "53      MAHARAJA WHITELINE 65 L Desert Air Cooler?????...          7999   3.0   \n",
       "120     MAHARAJA WHITELINE 65 L Desert Air Cooler?????...          7999   3.0   \n",
       "123     MAHARAJA WHITELINE 65 L Desert Air Cooler?????...          7999   5.0   \n",
       "140     MAHARAJA WHITELINE 65 L Desert Air Cooler?????...          7999   3.0   \n",
       "179     MAHARAJA WHITELINE 65 L Desert Air Cooler?????...          7999   3.0   \n",
       "...                                                   ...           ...   ...   \n",
       "204998  cello Pack of 18 Opalware Cello Dazzle Lush Fi...          1299   3.0   \n",
       "205012  cello Pack of 18 Opalware Cello Dazzle Lush Fi...          1299   5.0   \n",
       "205014  cello Pack of 18 Opalware Cello Dazzle Lush Fi...          1299   3.0   \n",
       "205016  cello Pack of 18 Opalware Cello Dazzle Lush Fi...          1299   3.0   \n",
       "205032  cello Pack of 18 Opalware Cello Dazzle Lush Fi...          1299   3.0   \n",
       "\n",
       "                  Review                                            Summary  \\\n",
       "53                  nice  received dalay 10 days cooler is ok when i was...   \n",
       "120            just okay                                        not so good   \n",
       "123     perfect product!  not working motors and very bad poor maharaja ...   \n",
       "140            just okay  product quality is very bad and fan blade brok...   \n",
       "179                 nice                cooler is good but very dirty smell   \n",
       "...                  ...                                                ...   \n",
       "204998         just okay  i expected that this dinner set might be compa...   \n",
       "205012         just wow!                                   plates are small   \n",
       "205014              fair                         dinner plates is too small   \n",
       "205016              fair                                         small size   \n",
       "205032         just okay                               bowls are small size   \n",
       "\n",
       "       Sentiment  \n",
       "53      negative  \n",
       "120     negative  \n",
       "123     negative  \n",
       "140     negative  \n",
       "179     negative  \n",
       "...          ...  \n",
       "204998  negative  \n",
       "205012  negative  \n",
       "205014  negative  \n",
       "205016  negative  \n",
       "205032  negative  \n",
       "\n",
       "[4731 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rate[(df_rate['Rate']>=3) & (df_rate['Sentiment']=='negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d0f2002",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>3.0</td>\n",
       "      <td>fair</td>\n",
       "      <td>the quality is good but the power of air is de...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nice</td>\n",
       "      <td>very nice</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>MAHARAJA WHITELINE 65 L Desert Air Cooler?????...</td>\n",
       "      <td>7999</td>\n",
       "      <td>3.0</td>\n",
       "      <td>decent product</td>\n",
       "      <td>great deal 65 l quite big tank sufficient cool...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>MAHARAJA WHITELINE 65 L Desert Air Cooler?????...</td>\n",
       "      <td>7999</td>\n",
       "      <td>3.0</td>\n",
       "      <td>very satisfactory</td>\n",
       "      <td>the good things1 very well packed good amount ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>MAHARAJA WHITELINE 65 L Desert Air Cooler?????...</td>\n",
       "      <td>7999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>worthless</td>\n",
       "      <td>the product doesnt cool as rated by other cust...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204981</th>\n",
       "      <td>cello Pack of 18 Opalware Cello Dazzle Lush Fi...</td>\n",
       "      <td>1299</td>\n",
       "      <td>3.0</td>\n",
       "      <td>good</td>\n",
       "      <td>better</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204987</th>\n",
       "      <td>cello Pack of 18 Opalware Cello Dazzle Lush Fi...</td>\n",
       "      <td>1299</td>\n",
       "      <td>3.0</td>\n",
       "      <td>decent product</td>\n",
       "      <td>it could be better</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204989</th>\n",
       "      <td>cello Pack of 18 Opalware Cello Dazzle Lush Fi...</td>\n",
       "      <td>1299</td>\n",
       "      <td>3.0</td>\n",
       "      <td>fair</td>\n",
       "      <td>not too much goodthe weight of the set is very...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205011</th>\n",
       "      <td>cello Pack of 18 Opalware Cello Dazzle Lush Fi...</td>\n",
       "      <td>1299</td>\n",
       "      <td>3.0</td>\n",
       "      <td>good</td>\n",
       "      <td>quality is good but size is very small</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205049</th>\n",
       "      <td>cello Pack of 18 Opalware Cello Dazzle Lush Fi...</td>\n",
       "      <td>1299</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nice</td>\n",
       "      <td>very nice and fast delivery</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11924 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             product_name product_price  Rate  \\\n",
       "2       Candes 12 L Room/Personal Air Cooler??????(Whi...          3999   3.0   \n",
       "7       Candes 12 L Room/Personal Air Cooler??????(Whi...          3999   3.0   \n",
       "43      MAHARAJA WHITELINE 65 L Desert Air Cooler?????...          7999   3.0   \n",
       "45      MAHARAJA WHITELINE 65 L Desert Air Cooler?????...          7999   3.0   \n",
       "59      MAHARAJA WHITELINE 65 L Desert Air Cooler?????...          7999   1.0   \n",
       "...                                                   ...           ...   ...   \n",
       "204981  cello Pack of 18 Opalware Cello Dazzle Lush Fi...          1299   3.0   \n",
       "204987  cello Pack of 18 Opalware Cello Dazzle Lush Fi...          1299   3.0   \n",
       "204989  cello Pack of 18 Opalware Cello Dazzle Lush Fi...          1299   3.0   \n",
       "205011  cello Pack of 18 Opalware Cello Dazzle Lush Fi...          1299   3.0   \n",
       "205049  cello Pack of 18 Opalware Cello Dazzle Lush Fi...          1299   3.0   \n",
       "\n",
       "                   Review                                            Summary  \\\n",
       "2                    fair  the quality is good but the power of air is de...   \n",
       "7                    nice                                          very nice   \n",
       "43         decent product  great deal 65 l quite big tank sufficient cool...   \n",
       "45      very satisfactory  the good things1 very well packed good amount ...   \n",
       "59              worthless  the product doesnt cool as rated by other cust...   \n",
       "...                   ...                                                ...   \n",
       "204981               good                                             better   \n",
       "204987     decent product                                 it could be better   \n",
       "204989               fair  not too much goodthe weight of the set is very...   \n",
       "205011               good             quality is good but size is very small   \n",
       "205049               nice                        very nice and fast delivery   \n",
       "\n",
       "       Sentiment  \n",
       "2       positive  \n",
       "7       positive  \n",
       "43      positive  \n",
       "45      positive  \n",
       "59      positive  \n",
       "...          ...  \n",
       "204981  positive  \n",
       "204987  positive  \n",
       "204989  positive  \n",
       "205011  positive  \n",
       "205049  positive  \n",
       "\n",
       "[11924 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rate[(df_rate['Rate']<=3) & (df_rate['Sentiment']=='positive')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e91ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned=df_rate[((df_rate['Rate']>=3) & (df_rate['Sentiment']=='positive')) | ((df_rate['Rate']<=3) & (df_rate['Sentiment']=='negative')) | (df_rate['Sentiment']=='neutral')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1090cf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "105a634b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "positive    164571\n",
       "negative     26523\n",
       "neutral      10239\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1db41dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "958"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['product_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "715abecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name         0\n",
       "product_price        0\n",
       "Rate                 0\n",
       "Review           24299\n",
       "Summary             11\n",
       "Sentiment            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf29db",
   "metadata": {},
   "source": [
    "Removing the missing Summary rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b294f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.dropna(subset=['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dd87ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201322"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71693335",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>great cooler excellent air flow and for this p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>best budget 2 fit cooler nice cooling</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>the quality is good but the power of air is de...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>very bad product its a only a fan</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>ok ok product</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name  \\\n",
       "0  Candes 12 L Room/Personal Air Cooler??????(Whi...   \n",
       "1  Candes 12 L Room/Personal Air Cooler??????(Whi...   \n",
       "2  Candes 12 L Room/Personal Air Cooler??????(Whi...   \n",
       "3  Candes 12 L Room/Personal Air Cooler??????(Whi...   \n",
       "4  Candes 12 L Room/Personal Air Cooler??????(Whi...   \n",
       "\n",
       "                                             Summary Sentiment  \n",
       "0  great cooler excellent air flow and for this p...  positive  \n",
       "1              best budget 2 fit cooler nice cooling  positive  \n",
       "2  the quality is good but the power of air is de...  positive  \n",
       "3                  very bad product its a only a fan  negative  \n",
       "4                                      ok ok product   neutral  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary=df_cleaned[['product_name', 'Summary','Sentiment']]\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77f5d250",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name    0\n",
       "Summary         0\n",
       "Sentiment       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1dcb9f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "positive    164565\n",
       "negative     26523\n",
       "neutral      10234\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bc96d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentiment_counts=df_summary['Sentiment'].value_counts()\n",
    "total_sentiments = len(df_summary['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13eec240",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "positive    81.742184\n",
       "negative    13.174417\n",
       "neutral      5.083399\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sentiment_counts / total_sentiments) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec6c12",
   "metadata": {},
   "source": [
    "This is a very imbalanced dataset which can cause bias towards one class. So I am going to upsample the Negative and Neutral classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51592b28",
   "metadata": {},
   "source": [
    "Splitting the data in train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6d4de9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_summary['Summary']\n",
    "\n",
    "y = df_summary['Sentiment']\n",
    "\n",
    "# Step 3: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b685250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10135</th>\n",
       "      <td>quality is nice but go for one larger size</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79285</th>\n",
       "      <td>this is the best</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86779</th>\n",
       "      <td>very nice product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86846</th>\n",
       "      <td>nice</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>awesome</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Summary Sentiment\n",
       "10135  quality is nice but go for one larger size  positive\n",
       "79285                            this is the best  positive\n",
       "86779                           very nice product  positive\n",
       "86846                                        nice  positive\n",
       "3819                                      awesome  positive"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the training features and labels into a single DataFrame\n",
    "train_dataset = pd.DataFrame({'Summary': X_train, 'Sentiment': y_train})\n",
    "\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a2dabb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "positive    50000\n",
      "negative    50000\n",
      "neutral     50000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_positive = train_dataset[train_dataset['Sentiment'] == 'positive']\n",
    "df_negative = train_dataset[train_dataset['Sentiment'] == 'negative']\n",
    "df_neutral = train_dataset[train_dataset['Sentiment'] == 'neutral']\n",
    "\n",
    "df_positive=df_positive.sample(n=50000)\n",
    "\n",
    "# Upsample minority class\n",
    "df_negative_upsampled = resample(df_negative, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=50000,    # to match majority class\n",
    "                                 random_state=42)  # reproducible results\n",
    "\n",
    "# Upsample minority class\n",
    "df_neutral_upsampled = resample(df_neutral, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=50000,    # to match majority class\n",
    "                                 random_state=42)  # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_positive, df_negative_upsampled, df_neutral_upsampled])\n",
    "\n",
    "print(df_upsampled['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8890865a",
   "metadata": {},
   "source": [
    "From Summary we are making TFIDF word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa560637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Vectorize text data (TF-IDF vectorization)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(df_upsampled['Summary'])\n",
    "y_train = df_upsampled['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7939458f",
   "metadata": {},
   "source": [
    "Used the TFIDF word vectors of Summary and Sentiment to train a random forest model. It took almost 20 minutes to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "080382b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in minutes: 33.377978920936584\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "\n",
    "# Step 4: Train a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "end_time=time.time()\n",
    "\n",
    "execution_time=end_time-start_time\n",
    "\n",
    "print(\"Time taken in minutes:\",execution_time/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393ec61",
   "metadata": {},
   "source": [
    "Process the test data and check the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "875ea988",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb720083",
   "metadata": {},
   "source": [
    "The evaluation metrics. The f1 score for the positive class is 97%, for the negative class 0.88%. But for the neutral class it's 0.54%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "78f143bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.92      0.88      5265\n",
      "     neutral       0.49      0.59      0.54      2082\n",
      "    positive       0.98      0.95      0.97     32918\n",
      "\n",
      "    accuracy                           0.93     40265\n",
      "   macro avg       0.77      0.82      0.79     40265\n",
      "weighted avg       0.94      0.93      0.93     40265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Predict on test data and evaluate\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fbf4423a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.98      0.99     50000\n",
      "     neutral       0.97      0.96      0.96     50000\n",
      "    positive       0.97      0.98      0.98     50000\n",
      "\n",
      "    accuracy                           0.98    150000\n",
      "   macro avg       0.98      0.98      0.98    150000\n",
      "weighted avg       0.98      0.98      0.98    150000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Predict on train data and evaluate\n",
    "y_pred_train = rf_classifier.predict(X_train)\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f794d5d",
   "metadata": {},
   "source": [
    "Prediction on given comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4d8b6384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={\"comment\":[\"The product was absolutely horrible. I can't believe they can rob me on this with high price and disgusting quality.\"]}\n",
    "\n",
    "df_comment = pd.DataFrame(dict)\n",
    "\n",
    "x = vectorizer.transform(df_comment[\"comment\"])\n",
    "\n",
    "rf_classifier.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bbcfa51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype=object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={\"comment\":[\"It's Ok product for me.\"]}\n",
    "\n",
    "df_comment = pd.DataFrame(dict)\n",
    "\n",
    "x = vectorizer.transform(df_comment[\"comment\"])\n",
    "\n",
    "rf_classifier.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "121b810e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={\"comment\":[\"I am in love with this dress. Also the brand is known for sustainable clothing so I can spend extra for that cause.\"]}\n",
    "\n",
    "df_comment = pd.DataFrame(dict)\n",
    "\n",
    "x = vectorizer.transform(df_comment[\"comment\"])\n",
    "\n",
    "rf_classifier.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "45781c54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "positive    50\n",
      "negative    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_positive = train_dataset[train_dataset['Sentiment'] == 'positive']\n",
    "df_negative = train_dataset[train_dataset['Sentiment'] == 'negative']\n",
    "df_neutral = train_dataset[train_dataset['Sentiment'] == 'neutral']\n",
    "\n",
    "df_positive=df_positive.sample(n=50)\n",
    "\n",
    "# Upsample minority class\n",
    "df_negative_upsampled = resample(df_negative, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=50,    # to match majority class\n",
    "                                 random_state=42)  # reproducible results\n",
    "\n",
    "# # Upsample minority class\n",
    "# df_neutral_upsampled = resample(df_neutral, \n",
    "#                                  replace=True,     # sample with replacement\n",
    "#                                  n_samples=50,    # to match majority class\n",
    "#                                  random_state=42)  # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_positive, df_negative_upsampled])\n",
    "\n",
    "print(df_upsampled['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "126fb0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_df=df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6f95bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the sentiments\n",
    "label_encoder = LabelEncoder()\n",
    "sampled_train_df['label'] = label_encoder.fit_transform(sampled_train_df['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1eee6514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the values for input_ids, token_type_ids, attention_mask\n",
    "def tokenize_text(text):\n",
    "    tokenized_input = tokenizer.encode_plus(text,\n",
    "        max_length=64,  # Set your desired maximum sequence length\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "        return_attention_mask=True)\n",
    "    return tokenized_input\n",
    "\n",
    "sampled_train_df[\"tokenized_input\"]=sampled_train_df['Summary'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "7ca6e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_df[\"features\"]=sampled_train_df.apply(lambda row: make_training_data(row['tokenized_input'], row['label']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "fe5fd0d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "positive    50\n",
      "negative    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sampled_train_df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "329bec69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Validation Loss: 0.9291058580080668, Validation Accuracy: 0.5\n",
      "Epoch 2/2, Validation Loss: 0.8157300353050232, Validation Accuracy: 0.65\n",
      "Execution time in minutes: 5.719256309668223\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "# Split data\n",
    "train_df, val_df = train_test_split(sampled_train_df, test_size=0.2, random_state=42, stratify=sampled_train_df['label'])\n",
    "\n",
    "train_dataset = train_df['features'].tolist()\n",
    "val_dataset = val_df['features'].tolist()\n",
    "\n",
    "# DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# Load BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "def train(model, train_dataloader, optimizer):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation loop\n",
    "def evaluate(model, val_dataloader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == batch['labels']).sum().item()\n",
    "            total += batch['labels'].size(0)\n",
    "    accuracy = correct / total\n",
    "    return val_loss / len(val_dataloader), accuracy\n",
    "\n",
    "# Train and evaluate the model\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_dataloader, optimizer)\n",
    "    val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "# Save the trained model\n",
    "output_dir = \"./SA_model_BERT_Downsample\"\n",
    "model.save_pretrained(output_dir)\n",
    "    \n",
    "end_time=time.time()\n",
    "\n",
    "execution_time=end_time-start_time\n",
    "\n",
    "print(\"Execution time in minutes:\",execution_time/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "841677ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "negative    40\n",
      "positive    40\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6ecdda42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "positive    10\n",
      "negative    10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(val_df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "256f0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names=['negative','positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "fec3e7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negative', 1: 'positive'}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {k: v for v, k in enumerate(label_names)}\n",
    "id2label = {v: k for v, k in enumerate(label_names)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "645f90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(Sentence):\n",
    "    \n",
    "    inputs = tokenizer(Sentence, return_tensors=\"pt\")\n",
    "    \n",
    "    # Step 2: Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Assuming your TokenClassifierOutput object is named 'output'\n",
    "    logits = outputs.logits\n",
    "\n",
    "#     # Apply softmax to get probabilities\n",
    "#     probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # Get the predicted labels (classes with highest probability)\n",
    "    predicted_labels = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    predicted_labels = predicted_labels.tolist()\n",
    "\n",
    "    labels = id2label[predicted_labels[0]]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "fe94f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[\"Predicted Sentiment\"]=val_df[\"Summary\"].apply(get_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "2f9bff1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      1.00      0.74        10\n",
      "    positive       1.00      0.30      0.46        10\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.79      0.65      0.60        20\n",
      "weighted avg       0.79      0.65      0.60        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_df[\"Sentiment\"], val_df[\"Predicted Sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "1588dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Predicted Sentiment\"]=train_df[\"Summary\"].apply(get_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b519a3b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.97      0.85        40\n",
      "    positive       0.96      0.68      0.79        40\n",
      "\n",
      "    accuracy                           0.82        80\n",
      "   macro avg       0.86      0.82      0.82        80\n",
      "weighted avg       0.86      0.82      0.82        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_df[\"Sentiment\"], train_df[\"Predicted Sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "a9cccd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "positive    50\n",
      "negative    50\n",
      "neutral     50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_positive = train_dataset[train_dataset['Sentiment'] == 'positive']\n",
    "df_negative = train_dataset[train_dataset['Sentiment'] == 'negative']\n",
    "df_neutral = train_dataset[train_dataset['Sentiment'] == 'neutral']\n",
    "\n",
    "df_positive=df_positive.sample(n=50)\n",
    "\n",
    "df_negative=df_negative.sample(n=50)\n",
    "\n",
    "df_neutral=df_neutral.sample(n=50)\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_downsampled = pd.concat([df_positive, df_negative, df_neutral])\n",
    "\n",
    "print(df_downsampled['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "6fbe01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_df=df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "b66a2006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the sentiments\n",
    "label_encoder = LabelEncoder()\n",
    "sampled_train_df['label'] = label_encoder.fit_transform(sampled_train_df['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "59a83a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the values for input_ids, token_type_ids, attention_mask\n",
    "def tokenize_text(text):\n",
    "    tokenized_input = tokenizer.encode_plus(text,\n",
    "        max_length=64,  # Set your desired maximum sequence length\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "        return_attention_mask=True)\n",
    "    return tokenized_input\n",
    "\n",
    "sampled_train_df[\"tokenized_input\"]=sampled_train_df['Summary'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e5dd1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_df[\"features\"]=sampled_train_df.apply(lambda row: make_training_data(row['tokenized_input'], row['label']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "8deff19a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "positive    50\n",
      "negative    50\n",
      "neutral     50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sampled_train_df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "b9a2f07e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Validation Loss: 1.0581064522266388, Validation Accuracy: 0.6\n",
      "Epoch 2/2, Validation Loss: 1.0078518986701965, Validation Accuracy: 0.5333333333333333\n",
      "Execution time in minutes: 8.066687500476837\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "# Split data\n",
    "train_df, val_df = train_test_split(sampled_train_df, test_size=0.2, random_state=42, stratify=sampled_train_df['label'])\n",
    "\n",
    "train_dataset = train_df['features'].tolist()\n",
    "val_dataset = val_df['features'].tolist()\n",
    "\n",
    "# DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# Load BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "def train(model, train_dataloader, optimizer):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation loop\n",
    "def evaluate(model, val_dataloader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == batch['labels']).sum().item()\n",
    "            total += batch['labels'].size(0)\n",
    "    accuracy = correct / total\n",
    "    return val_loss / len(val_dataloader), accuracy\n",
    "\n",
    "# Train and evaluate the model\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_dataloader, optimizer)\n",
    "    val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "# Save the trained model\n",
    "output_dir = \"./SA_model_BERT_Downsample_negposneu\"\n",
    "model.save_pretrained(output_dir)\n",
    "    \n",
    "end_time=time.time()\n",
    "\n",
    "execution_time=end_time-start_time\n",
    "\n",
    "print(\"Execution time in minutes:\",execution_time/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "d4481763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_input</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34875</th>\n",
       "      <td>very bad</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(2200), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56827</th>\n",
       "      <td>this plazzo is comfortable and nice fabric</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(2023), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128259</th>\n",
       "      <td>average</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(2779), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102858</th>\n",
       "      <td>pros vibrant easy installation consexpected to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(4013), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179864</th>\n",
       "      <td>average</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(2779), tens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Summary Sentiment  label  \\\n",
       "34875                                            very bad  negative      0   \n",
       "56827          this plazzo is comfortable and nice fabric  positive      2   \n",
       "128259                                            average   neutral      1   \n",
       "102858  pros vibrant easy installation consexpected to...  negative      0   \n",
       "179864                                            average   neutral      1   \n",
       "\n",
       "                                    tokenized_input  \\\n",
       "34875   [input_ids, token_type_ids, attention_mask]   \n",
       "56827   [input_ids, token_type_ids, attention_mask]   \n",
       "128259  [input_ids, token_type_ids, attention_mask]   \n",
       "102858  [input_ids, token_type_ids, attention_mask]   \n",
       "179864  [input_ids, token_type_ids, attention_mask]   \n",
       "\n",
       "                                                 features  \n",
       "34875   {'input_ids': [tensor(101), tensor(2200), tens...  \n",
       "56827   {'input_ids': [tensor(101), tensor(2023), tens...  \n",
       "128259  {'input_ids': [tensor(101), tensor(2779), tens...  \n",
       "102858  {'input_ids': [tensor(101), tensor(4013), tens...  \n",
       "179864  {'input_ids': [tensor(101), tensor(2779), tens...  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "12686e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names=['negative','neutral','positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "0ae6eea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negative', 1: 'neutral', 2: 'positive'}"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {k: v for v, k in enumerate(label_names)}\n",
    "id2label = {v: k for v, k in enumerate(label_names)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "8cf2c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(Sentence):\n",
    "    \n",
    "    inputs = tokenizer(Sentence, return_tensors=\"pt\")\n",
    "    \n",
    "    # Step 2: Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Assuming your TokenClassifierOutput object is named 'output'\n",
    "    logits = outputs.logits\n",
    "\n",
    "#     # Apply softmax to get probabilities\n",
    "#     probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # Get the predicted labels (classes with highest probability)\n",
    "    predicted_labels = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    predicted_labels = predicted_labels.tolist()\n",
    "\n",
    "    labels = id2label[predicted_labels[0]]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "1ec87a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[\"Predicted Sentiment\"]=val_df[\"Summary\"].apply(get_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "19fa8d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.70      0.78        10\n",
      "     neutral       0.41      0.90      0.56        10\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.53        30\n",
      "   macro avg       0.43      0.53      0.45        30\n",
      "weighted avg       0.43      0.53      0.45        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samapti\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Samapti\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Samapti\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_df[\"Sentiment\"], val_df[\"Predicted Sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "232eb96a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "positive    3000\n",
      "negative    3000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_positive = train_dataset[train_dataset['Sentiment'] == 'positive']\n",
    "df_negative = train_dataset[train_dataset['Sentiment'] == 'negative']\n",
    "df_neutral = train_dataset[train_dataset['Sentiment'] == 'neutral']\n",
    "\n",
    "df_positive=df_positive.sample(n=3000)\n",
    "\n",
    "# Upsample minority class\n",
    "df_negative_upsampled = resample(df_negative, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=3000,    # to match majority class\n",
    "                                 random_state=42)  # reproducible results\n",
    "\n",
    "# # Upsample minority class\n",
    "# df_neutral_upsampled = resample(df_neutral, \n",
    "#                                  replace=True,     # sample with replacement\n",
    "#                                  n_samples=50,    # to match majority class\n",
    "#                                  random_state=42)  # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_positive, df_negative_upsampled])\n",
    "\n",
    "print(df_upsampled['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cee96306",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_df=df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "919a400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the sentiments\n",
    "label_encoder = LabelEncoder()\n",
    "sampled_train_df['label'] = label_encoder.fit_transform(sampled_train_df['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "522386ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the values for input_ids, token_type_ids, attention_mask\n",
    "def tokenize_text(text):\n",
    "    tokenized_input = tokenizer.encode_plus(text,\n",
    "        max_length=64,  # Set your desired maximum sequence length\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "        return_attention_mask=True)\n",
    "    return tokenized_input\n",
    "\n",
    "sampled_train_df[\"tokenized_input\"]=sampled_train_df['Summary'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1eb62ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_data(tokenized_input,adjusted_labels):\n",
    "    input_ids=tokenized_input[\"input_ids\"][0]\n",
    "    token_type_ids=tokenized_input[\"token_type_ids\"][0]\n",
    "    attention_mask=tokenized_input[\"attention_mask\"][0]\n",
    "    \n",
    "    labels=torch.tensor(adjusted_labels)\n",
    "    features={\n",
    "        'input_ids': input_ids,\n",
    "        'token_type_ids':token_type_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d42f35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_df[\"features\"]=sampled_train_df.apply(lambda row: make_training_data(row['tokenized_input'], row['label']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8e4d188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_input</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>nice product</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(3835), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185952</th>\n",
       "      <td>good product best quality in affordable price ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(2204), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140011</th>\n",
       "      <td>awesome dress my baby so happy thank you flipkart</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(12476), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145401</th>\n",
       "      <td>osm product more soft</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(9808), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22802</th>\n",
       "      <td>i am enjoying using this food processor it rea...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(1045), tens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Summary Sentiment  label  \\\n",
       "14375                                        nice product  positive      1   \n",
       "185952  good product best quality in affordable price ...  positive      1   \n",
       "140011  awesome dress my baby so happy thank you flipkart  positive      1   \n",
       "145401                              osm product more soft  positive      1   \n",
       "22802   i am enjoying using this food processor it rea...  positive      1   \n",
       "\n",
       "                                    tokenized_input  \\\n",
       "14375   [input_ids, token_type_ids, attention_mask]   \n",
       "185952  [input_ids, token_type_ids, attention_mask]   \n",
       "140011  [input_ids, token_type_ids, attention_mask]   \n",
       "145401  [input_ids, token_type_ids, attention_mask]   \n",
       "22802   [input_ids, token_type_ids, attention_mask]   \n",
       "\n",
       "                                                 features  \n",
       "14375   {'input_ids': [tensor(101), tensor(3835), tens...  \n",
       "185952  {'input_ids': [tensor(101), tensor(2204), tens...  \n",
       "140011  {'input_ids': [tensor(101), tensor(12476), ten...  \n",
       "145401  {'input_ids': [tensor(101), tensor(9808), tens...  \n",
       "22802   {'input_ids': [tensor(101), tensor(1045), tens...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f6a9327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e168639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "positive    3000\n",
      "negative    3000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sampled_train_df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67f10d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Summary            0\n",
       "Sentiment          0\n",
       "label              0\n",
       "tokenized_input    0\n",
       "features           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "267a20b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Validation Loss: 0.09293060516317686, Validation Accuracy: 0.9716666666666667\n",
      "Epoch 2/2, Validation Loss: 0.08796297380778317, Validation Accuracy: 0.9716666666666667\n",
      "Execution time in minutes: 304.3290209929148\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "# Split data\n",
    "train_df, val_df = train_test_split(sampled_train_df, test_size=0.2, random_state=42, stratify=sampled_train_df['label'])\n",
    "\n",
    "train_dataset = train_df['features'].tolist()\n",
    "val_dataset = val_df['features'].tolist()\n",
    "\n",
    "# DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# Load BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "def train(model, train_dataloader, optimizer):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation loop\n",
    "def evaluate(model, val_dataloader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == batch['labels']).sum().item()\n",
    "            total += batch['labels'].size(0)\n",
    "    accuracy = correct / total\n",
    "    return val_loss / len(val_dataloader), accuracy\n",
    "\n",
    "# Train and evaluate the model\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_dataloader, optimizer)\n",
    "    val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "# Save the trained model\n",
    "output_dir = \"./SA_model_BERT_Downsample_Big_negpos\"\n",
    "model.save_pretrained(output_dir)\n",
    "    \n",
    "end_time=time.time()\n",
    "\n",
    "execution_time=end_time-start_time\n",
    "\n",
    "print(\"Execution time in minutes:\",execution_time/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8760bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names=['negative','positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81b59964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negative', 1: 'positive'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {k: v for v, k in enumerate(label_names)}\n",
    "id2label = {v: k for v, k in enumerate(label_names)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8e7abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(Sentence):\n",
    "    \n",
    "    inputs = tokenizer(Sentence, return_tensors=\"pt\")\n",
    "    \n",
    "    # Step 2: Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Assuming your TokenClassifierOutput object is named 'output'\n",
    "    logits = outputs.logits\n",
    "\n",
    "#     # Apply softmax to get probabilities\n",
    "#     probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # Get the predicted labels (classes with highest probability)\n",
    "    predicted_labels = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    predicted_labels = predicted_labels.tolist()\n",
    "\n",
    "    labels = id2label[predicted_labels[0]]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d07fce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[\"Predicted Sentiment\"]=val_df[\"Summary\"].apply(get_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16abe54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97       600\n",
      "    positive       0.99      0.95      0.97       600\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.97      0.97      0.97      1200\n",
      "weighted avg       0.97      0.97      0.97      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_df[\"Sentiment\"], val_df[\"Predicted Sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80bbaf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv(\"Final_BERT_Predicted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab31b02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "positive    2000\n",
      "negative    2000\n",
      "neutral     2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_positive = train_dataset[train_dataset['Sentiment'] == 'positive']\n",
    "df_negative = train_dataset[train_dataset['Sentiment'] == 'negative']\n",
    "df_neutral = train_dataset[train_dataset['Sentiment'] == 'neutral']\n",
    "\n",
    "df_positive=df_positive.sample(n=2000)\n",
    "\n",
    "# Upsample minority class\n",
    "df_negative_upsampled = resample(df_negative, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=2000,    # to match majority class\n",
    "                                 random_state=42)  # reproducible results\n",
    "\n",
    "# Upsample minority class\n",
    "df_neutral_upsampled = resample(df_neutral, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=2000,    # to match majority class\n",
    "                                 random_state=42)  # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_positive, df_negative_upsampled,df_neutral_upsampled])\n",
    "\n",
    "print(df_upsampled['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ad3089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_df=df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7e90bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the sentiments\n",
    "label_encoder = LabelEncoder()\n",
    "sampled_train_df['label'] = label_encoder.fit_transform(sampled_train_df['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5561e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the values for input_ids, token_type_ids, attention_mask\n",
    "def tokenize_text(text):\n",
    "    tokenized_input = tokenizer.encode_plus(text,\n",
    "        max_length=64,  # Set your desired maximum sequence length\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "        return_attention_mask=True)\n",
    "    return tokenized_input\n",
    "\n",
    "sampled_train_df[\"tokenized_input\"]=sampled_train_df['Summary'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ddc92ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_data(tokenized_input,adjusted_labels):\n",
    "    input_ids=tokenized_input[\"input_ids\"][0]\n",
    "    token_type_ids=tokenized_input[\"token_type_ids\"][0]\n",
    "    attention_mask=tokenized_input[\"attention_mask\"][0]\n",
    "    \n",
    "    labels=torch.tensor(adjusted_labels)\n",
    "    features={\n",
    "        'input_ids': input_ids,\n",
    "        'token_type_ids':token_type_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d04a2dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_df[\"features\"]=sampled_train_df.apply(lambda row: make_training_data(row['tokenized_input'], row['label']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a86556ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_input</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145623</th>\n",
       "      <td>perfect</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(3819), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189493</th>\n",
       "      <td>nice</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(3835), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53379</th>\n",
       "      <td>so nice</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(2061), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54998</th>\n",
       "      <td>awesome nice</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(12476), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71118</th>\n",
       "      <td>v good</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>{'input_ids': [tensor(101), tensor(1058), tens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Summary Sentiment  label  \\\n",
       "145623       perfect  positive      2   \n",
       "189493          nice  positive      2   \n",
       "53379        so nice  positive      2   \n",
       "54998   awesome nice  positive      2   \n",
       "71118         v good  positive      2   \n",
       "\n",
       "                                    tokenized_input  \\\n",
       "145623  [input_ids, token_type_ids, attention_mask]   \n",
       "189493  [input_ids, token_type_ids, attention_mask]   \n",
       "53379   [input_ids, token_type_ids, attention_mask]   \n",
       "54998   [input_ids, token_type_ids, attention_mask]   \n",
       "71118   [input_ids, token_type_ids, attention_mask]   \n",
       "\n",
       "                                                 features  \n",
       "145623  {'input_ids': [tensor(101), tensor(3819), tens...  \n",
       "189493  {'input_ids': [tensor(101), tensor(3835), tens...  \n",
       "53379   {'input_ids': [tensor(101), tensor(2061), tens...  \n",
       "54998   {'input_ids': [tensor(101), tensor(12476), ten...  \n",
       "71118   {'input_ids': [tensor(101), tensor(1058), tens...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "33021883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1a459f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "positive    2000\n",
      "negative    2000\n",
      "neutral     2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sampled_train_df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ffab543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Summary            0\n",
       "Sentiment          0\n",
       "label              0\n",
       "tokenized_input    0\n",
       "features           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb055cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "# Split data\n",
    "train_df, val_df = train_test_split(sampled_train_df, test_size=0.2, random_state=42, stratify=sampled_train_df['label'])\n",
    "\n",
    "train_dataset = train_df['features'].tolist()\n",
    "val_dataset = val_df['features'].tolist()\n",
    "\n",
    "# DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# Load BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "def train(model, train_dataloader, optimizer):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation loop\n",
    "def evaluate(model, val_dataloader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == batch['labels']).sum().item()\n",
    "            total += batch['labels'].size(0)\n",
    "    accuracy = correct / total\n",
    "    return val_loss / len(val_dataloader), accuracy\n",
    "\n",
    "# Train and evaluate the model\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_dataloader, optimizer)\n",
    "    val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "# Save the trained model\n",
    "output_dir = \"./SA_model_BERT_Downsample_Big_negposneu\"\n",
    "model.save_pretrained(output_dir)\n",
    "    \n",
    "end_time=time.time()\n",
    "\n",
    "execution_time=end_time-start_time\n",
    "\n",
    "print(\"Execution time in minutes:\",execution_time/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f69ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names=['negative','neutral','positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {k: v for v, k in enumerate(label_names)}\n",
    "id2label = {v: k for v, k in enumerate(label_names)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(Sentence):\n",
    "    \n",
    "    inputs = tokenizer(Sentence, return_tensors=\"pt\")\n",
    "    \n",
    "    # Step 2: Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Assuming your TokenClassifierOutput object is named 'output'\n",
    "    logits = outputs.logits\n",
    "\n",
    "#     # Apply softmax to get probabilities\n",
    "#     probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # Get the predicted labels (classes with highest probability)\n",
    "    predicted_labels = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    predicted_labels = predicted_labels.tolist()\n",
    "\n",
    "    labels = id2label[predicted_labels[0]]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[\"Predicted Sentiment\"]=val_df[\"Summary\"].apply(get_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0616ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(val_df[\"Sentiment\"], val_df[\"Predicted Sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f9f6be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550bc43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396973b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d17ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1c77dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Predicted_Sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "2dd2efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Predicted Sentiment\"]=df[\"Summary\"].apply(get_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "ac68db0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.27      0.71      0.39       163\n",
      "     neutral       0.06      0.71      0.10        65\n",
      "    positive       1.00      0.00      0.00      1022\n",
      "\n",
      "    accuracy                           0.13      1250\n",
      "   macro avg       0.44      0.47      0.16      1250\n",
      "weighted avg       0.86      0.13      0.06      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df[\"Sentiment\"], df[\"Predicted Sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2d11c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
